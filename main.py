"""
Title: Generative Adversarial Network - Video Frame Interpolation (GAN-VFI)
Author: Chris McDonald
Date: March 24, 2024

Description:
This is the main script for the GAN-VFI Project, all other scripts will be called from here.
It controls video dataset loading, both (generator & discriminator) of the neural networks, and the training cycle.

Usage:
Run the script using `python main.py` in a terminal.
Make sure python is installed along with the necessary libraries.

Notes:
This file connects multiple python scripts to train the GAN on a local copy of the Vimeo90k dataset:
dataset_statistics.py   - Calculates the mean and standard deviation of the pixels in the dataset, separated by channels (RGB).
dataset_test.py         - Tests if the dataset is properly loaded by plotting each set of frames into a figure.
dataset.py              - Defines the VimeoDataset Class which is used to load the dataset into a variable. All pixels are normalized
                        in the range [-1,1] by subtracting 127.5 and then dividing by 127.5
discriminator.py        - Defines the discriminator neural network for the (DCGAN) implementation. Condenses the multi-dimensional dataset into a single channel 
                        of the probability that the frames have been generated by the Generator. 
format_time.py          - Takes an input of the start and end time of the section of the script being measured using the time module, and transforms it into 
                        a duration of days, hours, minutes, seconds and milliseconds.
generator.py            - Defines the generator neural network for the DCGAN implementation. Transforming random noise into meaningful data, attempting to match the dataset.
"""

import torch                                # PyTorch library - Used for tensors and neural networks in the deep learning model.
from torch.utils.data import DataLoader     # DataLoader class of torch.utils.data module - Used for loading dataset into batches.
from torchvision import transforms          # Transforms module of torchvision library - Used for transformation functions applied to images.
import torch.nn as nn                       # Neural network module of of torch library - Used for defining weights of each layer of the models.
import numpy as np                          # Numpy library - Used for creating and modifying matrices of various dimensions.
import random                               # random library - Used for setting the seed in order to have reproducable code.
import torch.optim as optim                 # optim module of torch library - Used for defining the optimizers which train the neural networks.
import time                                 # time library - Used for calculating the duration of various sections of the script.
import math                                 # math library - Used for calculating values for visualization e.g. Number of batches based on dataset and batch sizes.
import matplotlib.pyplot as plt
import torchvision.utils as vutils
import matplotlib.animation as animation
from tqdm import tqdm

# Importing other scripts
from dataset import VimeoDataset                                # VimeoDataset class from dataset.py
from generator import Generator2D as Generator                  # Generator and Generator2D classes from generator.py
from discriminator import Discriminator2D as Discriminator      # Discriminator and Discriminator2D classes from discriminator.py
from format_time import format_duration                         # format_duration function from format_time.py
from dataset_statistics import dataset_statistics               # dataset_statistics class from dataset_statistics.py
from dataset_test import dataset_plot                           # dataset_plot function from dataset_test.py
from gan import GAN

# Attempts to use a GPU if available, otherwise uses the users CPU.
try:
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
except Exception as e:
    print(f"Error during GPU initialization: {e}")
    device = torch.device("cpu")

print(f"Selected device: {device} ({torch.cuda.get_device_name(device.index)}), number of GPU's: {torch.cuda.device_count()}")

# Set seed
manualSeed = 1024
random.seed(manualSeed)
torch.manual_seed(manualSeed)
torch.use_deterministic_algorithms(True)

# Hyperparameters
batch_size = 32             # Number of videos per "batch"
latent_dim = 100            # 
learning_rate = 0.0002
beta1 = 0.5
beta2 = 0.999
num_epochs = 100
worker_threads = 2
colour_channels = 3
lambda_temporal = 0.1
lambda_depth = 0.01

# Global variables
training_batches = int()
training_remainder = int()

train_dataset_mean = [0.3675, 0.3393, 0.3194]
train_dataset_standard_deviation = [0.2111, 0.1870, 0.1717]

dataset_mean = [0.36746213, 0.33925724, 0.31939113]
dataset_standard_deviation = [0.20665579, 0.19933419, 0.19278685]

# Creating DataLoaders for training and testing

train_dataset = VimeoDataset(root_dir='src\\vimeo_septuplet', split='train')
train_data = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=worker_threads)

training_batches = math.ceil(len(train_dataset) / batch_size)
training_remainder = len(train_dataset) % batch_size
#print(f"Dataset has {len(train_dataset)} videos, split into {training_batches} batches of size {batch_size} where the last batch consists of {training_remainder} videos")

test_dataset = VimeoDataset(root_dir='src\\vimeo_septuplet', split='test')
test_data = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=worker_threads)

# Initialize components

N, in_channels, height, width = 8, 3, 512, 512
generator = Generator(latent_dim, in_channels, N).to(device)
discriminator = Discriminator(in_channels, N).to(device)

#gan_model = GAN(gen=generator, dis=discriminator, latent_dim=latent_dim, lr=learning_rate)

def initialize_weights(models):
    for model in models:
        for m in model.modules():
            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):
                nn.init.normal_(m.weight.data, 0.0, 0.02)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.normal_(m.weight.data, 1.0, 0.02)
                nn.init.constant_(m.bias.data, 0)

#initialize_weights([generator, discriminator])

def weights_init(models):
    classname = models.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(models.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(models.weight.data, 1.0, 0.02)
        nn.init.constant_(models.bias.data, 0)

generator.apply(weights_init)
discriminator.apply(weights_init)

# Loss functions
BCE_loss = nn.BCELoss()
#adversarial_loss = nn.BCELoss()
#temporal_loss = nn.MSELoss()
#depth_loss = nn.MSELoss()

fixed_noise = torch.randn(64, latent_dim, 1, 1, device=device) # Creates 64 noise vectors with 100 dimensions
real_label = 1.0
fake_label = 0.0

# Optimizers
optimizer_generator = optim.Adam(generator.parameters(), lr=learning_rate, betas=(beta1, beta2), weight_decay=learning_rate/num_epochs)
optimizer_discriminator = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(beta1, beta2), weight_decay=learning_rate/num_epochs)

# Analyzing preprocessing

if __name__ == '__main__':
    test_batch = next(iter(train_data))
    plt.axis("off")
    plt.title("Training images")
    frame_list = []
    frames, label = test_batch
    for i in range(batch_size):
        for j in range(7):
            frame_list.append(frames[j][i])

    print(len(frame_list)/7, len(frame_list)/batch_size, len(frame_list))

    plt.imshow(np.transpose(vutils.make_grid(frame_list, padding=1, normalize=True, nrow=14).cpu(),(1,2,0)))
    plt.show()

    generated_frames = []
    g_losses = []
    g_mean_preds = []
    d_losses = []
    d_fake_mean_preds = []
    d_real_mean_preds = []
    iteration = 0
    epoch_count = 0
    
    print(f"Starting the training loop for {num_epochs} epochs")
    for epoch in range(num_epochs):
        epoch_count += 1
        for batch_idx, data in enumerate(train_data):
            startt = time.time()
            progress_bar = tqdm(total=training_batches*num_epochs)
            progress_bar.update(1)
            progress_bar.set_description(f"Batch {batch_idx+1+(training_batches*(epoch_count-1))}/{training_batches*num_epochs} Epoch {epoch_count}/{num_epochs} ({(batch_idx+1+(training_batches*(epoch_count-1)))/(training_batches*num_epochs):.2f}%)")
            frames, label = data     
            frame_list = []

            for i in range(batch_size):
                for j in range(7):
                    frame_list.append(frames[j][i])

            frame_list = torch.stack(frame_list).to(device)      
            print("Disc")
            # # # # # # # # # # # # # # # #
            #    Training Discriminator   #
            # # # # # # # # # # # # # # # #

            discriminator.zero_grad()
            optimizer_discriminator.zero_grad()
            
            # All real data
            print("Disc with real")
            label = torch.full((batch_size*7,), real_label, dtype=torch.float, device=device)
            real_output = discriminator(frame_list).view(-1)
            d_real_error = BCE_loss(real_output, label)
            d_real_error.backward()
            d_real_mean_pred = real_output.mean().item()

            # All fake data
            print("Disc with fake")
            label.fill_(fake_label)
            noise = torch.randn(batch_size*7, latent_dim, 1, 1, device=device)
            fake_frames = generator(noise)
            fake_output = discriminator(fake_frames.detach()).view(-1)
            d_fake_error = BCE_loss(fake_output, label)
            d_fake_error.backward()
            d_fake_mean_pred = fake_output.mean().item()
            
            d_error = d_real_error + d_fake_error
            print("Optimizing disc parameters")
            optimizer_discriminator.step()
            print("Gen")
            # # # # # # # # # # # # # #
            #    Training Generator   #
            # # # # # # # # # # # # # #

            generator.zero_grad()
            optimizer_generator.zero_grad()
            print("Gen with fake")
            label.fill_(real_label) # Generator aims to have its data classified as real
            output = discriminator(fake_frames).view(-1)
            g_error = BCE_loss(output, label)
            g_error.backward()
            g_mean_pred = output.mean().item()
            print("Optimizing gen parameters")
            optimizer_generator.step()

            g_losses.append(g_error.item())
            d_losses.append(d_error.item())
            g_mean_preds.append(g_mean_pred)
            d_fake_mean_preds.append(d_fake_mean_pred)
            d_real_mean_preds.append(d_real_mean_pred)
            print("Appended results")

            if (iteration % 100 == 0) or ((epoch == num_epochs-1) and (i == len(train_data)-1)):
                with torch.no_grad():
                    fake = generator(fixed_noise).detach().cpu()
                generated_frames.append(vutils.make_grid(fake, padding=2, normalize=True, nrow=8))

            iteration += 1
            print("Loop finished")
            endt = time.time()
            dif = endt-startt
            print(f"{dif} seconds")

    torch.save(generator.state_dict(), f'models/epoch{num_epochs}/batch{batch_size}/lr{learning_rate}/generator_final.pth')
    torch.save(discriminator.state_dict(), f'models/epoch{num_epochs}/batch{batch_size}/lr{learning_rate}/discriminator_final.pth')

    plt.figure(figsize=(10,5))
    plt.title("Generator and Discriminator Loss During Training")
    plt.plot(g_losses,label="G")
    plt.plot(d_losses,label="D")
    plt.xlabel("iterations")
    plt.ylabel("Loss")
    plt.legend()
    plt.show()

    plt.figure(figsize=(10,5))
    plt.title("Mean Predictions")
    plt.plot(g_mean_preds,label="G")
    plt.plot(d_fake_mean_preds,label="D-Fake")
    plt.plot(d_real_mean_preds,label="D-Real")
    plt.xlabel("iterations")
    plt.ylabel("Probability")
    plt.legend()
    plt.show()

    fig = plt.figure(figsize=(8,8))
    plt.axis("off")
    images = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in generated_frames]
    animated_frames = animation.ArtistAnimation(fig, images, interval=1000, repeat_delay=1000, blit=True)
    plt.show()

